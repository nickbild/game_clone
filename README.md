# Neural Pong

*More details coming soon...*

I have cloned Pong with a neural network. The neural network is not playing Pong, it ***is*** Pong, and you play it.

<p align="center">
    <img src="https://raw.githubusercontent.com/nickbild/game_clone/refs/heads/main/media/playing.gif">
</p>

After designing a model architecture that is well-suited to learning the physics of the game, I was able to teach it all of the game rules and how to interpret user inputs by showing it hundreds of thousands of sequential frames captured during normal gameplay.

![](https://raw.githubusercontent.com/nickbild/game_clone/refs/heads/main/media/logo.jpg)

## How It Works

I wrote a simple [Pong-style game](https://github.com/nickbild/game_clone/blob/main/pong.py) using pygame. As each frame is displayed, it writes a text file containing information on the positions of the paddles, the position of the ball, and the state of the user inputs. This data, along with supplemental synthetic data that simulates a paddle miss (which is otherwise a rare event) that is generated by [this script](https://github.com/nickbild/game_clone/blob/main/gen_misses.py), is used to train an artificial neural network. The architecture is represented in the diagram below:

![](https://raw.githubusercontent.com/nickbild/game_clone/refs/heads/main/model_architecture.png) 

Whoah! All that to learn Pong? It may seem like overkill, but the physics are actually difficult to learn. I started out thinking I'd have this running in a few hours with a simple feedforward network, but it ended up taking months of spare time to get it working. The velocity inversion of the ball at bounces, the paddle hits and misses, and the issue of paddle movement and ball movement inappropriately being linked together, for instance, was very, very hard for any model I tried to learn. Aside from basic feedforward architectures, I also tried LSTM/GRU layers, convolutional layers, and (as it felt, anyway) just about everything else.

What ended up finally working was a Transformer-based architecture with multiple isolated branches and output heads. Next I'll go into a deep-dive of the model.

### Explaining the Model Architecture

The model is defined in the [training script](https://github.com/nickbild/game_clone/blob/main/train.py).

The model takes in a set of 4 sequential time points containing ball and paddle coordinates and user inputs. I also included a number of engineered features (e.g. ball velocity, distance from each edge, etc.) to aid the model in learning. The goal is to learn the physics of ball movement, bounces at the edges of the screen, paddle misses (point scored) or bounces, how to handle user input to adjust paddle positions, and to keep everything within bounds of the screen — basically everything that makes up a game of pong. This knowledge contained in the model is used to predict the next frame in the game, which then slides into the list of past frames as new predictions are made. So, initially a game is started with a seed of 4 time points of data, then the model does all the work. But that is for the inference stage, so I am getting ahead of myself.

The architecture uses branching to separate paddle and ball processing (divide-and-conquer for independent dynamics) to avoid learning inappropriate interactions, temporal modeling via attention (to capture sequence dependencies across frames), and a shared branch for integrating interactions (e.g., paddle-ball collisions for bounces).

A normalization layer scales features to mean=0, variance=1 based on training data statistics, because training would be much slower using absolute coordinates (much larger values). Next, a Gaussian noise layer adds a small amount of random noise to normalized inputs during training only to make the model more robust to unseen data.

Each player paddle has their own branch that is a simple feedforward layer that only looks at the paddle position and associated user input. This allows it to learn without being confused by irrelevant features.

All ball-related features are also isolated and fed into a branch of the network. This uses the self-attention of a Transformer to pick out the features that influence ball movement, which proved to be especially useful on edge cases (e.g. bounces) that other types of models just averaged out of existence.

After that, another independent branch takes in the output of the ball and paddle branches and merges them for processing by another Transformer. This picks up more complex interactions between the ball and paddle.

Finally, the paddle positions, ball position, and game state (normal/point scored) are predicted for the next frame.

### Playing the Model

The [inference script](https://github.com/nickbild/game_clone/blob/main/neural_pong.py) is used to play the game. It is given a set of 4 hard coded time points of input data initially to make the first prediction with. The results of the prediction are used to position elements on the screen. From that point forward, predictions move backward into the historical data that the model predicts the next frame from, along with keyboard data that is fed in to represent the user inputs. This process continues *ad infinitum*, with all logic being contained in the trained model. The inference script just handles drawing elements to the screen where the network says they should go — it contains no game logic whatsoever.

## About the Author

[Nick A. Bild, MS](https://nickbild79.firebaseapp.com/#!/)
